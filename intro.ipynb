{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Spark exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## README\n",
      "Download Spark binaries [here](http://spark.apache.org/downloads.html) or directly\n",
      "[here](http://www.apache.org/dyn/closer.cgi/spark/spark-1.2.0/spark-1.2.0-bin-hadoop2.4.tgz)\n",
      "\n",
      "Resources:\n",
      "\n",
      "+ [Spark Programming Guide (v1.2.0)](http://spark.apache.org/docs/latest/programming-guide.html)\n",
      "\n",
      "+ [Spark Python API Docs](http://spark.apache.org/docs/latest/api/python/index.html)\n",
      "\n",
      "+ [Spark training resources](http://databricks.com/spark-training-resources) and [code+data download](http://training.databricks.com/workshop/usb.zip) (thanks to *Databricks*)\n",
      "\n",
      "+ [pyspark-pictures](http://nbviewer.ipython.org/github/jkthompson/pyspark-pictures/blob/master/pyspark-pictures.ipynb) : Learn the pyspark API through pictures and simple examples (thanks to *jkthompson*)\n",
      "\n",
      "+ Spark on AWS (EC2), exercises applied to NLP (thanks to *utcompling*): [Ex1](https://github.com/utcompling/applied-nlp/wiki/Spark-AWS-Exercise1) [Ex2](https://github.com/utcompling/applied-nlp/wiki/Spark-AWS-Exercise2)\n",
      "\n",
      "+ [Spark on AWS (EMR)](https://aws.amazon.com/articles/4926593393724923): Run Spark and Spark SQL on Amazon Elastic MapReduce (thanks to *Amazon WS*) \n",
      "\n",
      "+ [Apache Spark Lessons Learned](http://files.meetup.com/14077672/Apache%20Spark%20Lessons%20Learned.pdf) thanks to *madhu.com*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hello Scala!\n",
      "\n",
      "Launch spark-shell (local, driver only):\n",
      "``./bin/spark-shell --master local[4]\n",
      "``\n",
      "\n",
      "Play with the spark-shell:\n",
      "```sc.getConf.toDebugString\n",
      "```\n",
      "\n",
      "Open SparkContext web UI in [localhost:4040](http://localhost:4040)\n",
      "\n",
      "Launch 1-machine \"cluster\" in localhost:\n",
      "``./sbin/start-all.sh\n",
      "``\n",
      "\n",
      "Open Spark master's web UI in [localhost:8080](http://localhost:8080)\n",
      "\n",
      "Launch spark-shell (localhost, driver and worker): \n",
      "``./bin/spark-shell --master spark://HOST:7077\n",
      "``"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Good Bye Scala! Hello Python!\n",
      "\n",
      "Launch pyspark shell (with ipython notebook support):\n",
      "\n",
      "``\n",
      "PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" ./bin/pyspark\n",
      "``"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Exercises"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.context import SparkContext\n",
      "print \"Running Spark Version %s\" % (sc.version)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running Spark Version 1.2.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.conf import SparkConf\n",
      "myconf = SparkConf()\n",
      "print myconf.toDebugString()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark.app.name=pyspark-shell\n",
        "spark.master=local[*]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [1, 2, 3, 4, 5]\n",
      "distData = sc.parallelize(data)\n",
      "print type(distData)\n",
      "distData"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pyspark.rdd.RDD'>\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:364"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distData.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "15"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distData.reduce(lambda a,b : a + b) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "15"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Configuration properties"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.conf import SparkConf\n",
      "myconf = SparkConf()\n",
      "myconf.set('spark.driver.memory', '512m').set(\"spark.app.name\", \"My spark app\")\n",
      "print myconf.toDebugString()\n",
      "sc = SparkContext(conf = myconf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark.app.name=My spark app\n",
        "spark.driver.memory=512m\n",
        "spark.master=local[*]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Another way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SparkContext.setSystemProperty(\"spark.app.name\", \"My spark app 2\")\n",
      "SparkContext.setSystemProperty('spark.driver.memory', '512m')\n",
      "print myconf.toDebugString()\n",
      "sc.stop()\n",
      "sc = SparkContext()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark.app.name=My spark app\n",
        "spark.driver.memory=512m\n",
        "spark.master=local[*]\n",
        "spark.rdd.compress=True\n",
        "spark.serializer.objectStreamReset=100\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Working with text files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = sc.textFile(\"data/graphx-wiki-vertices.txt\")\n",
      "lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "data/graphx-wiki-vertices.txt MappedRDD[1] at textFile at NativeMethodAccessorImpl.java:-2"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[u'6598434222544540151\\tAdelaide Hanscom Leeson',\n",
        " u'7814958205460279317\\tDavid Dodge (novelist)',\n",
        " u'3858831448322232257\\tHoward League for Penal Reform',\n",
        " u'1778261942684788432\\tChelsea Quinn Yarbro',\n",
        " u'4201849915685975228\\tDominick Montiglio']"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "22424"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lineLengths = lines.map(lambda s: len(s))\n",
      "lineLengths.reduce(lambda a, b: a + b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "923158"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def findspains(line):\n",
      "    return any(s in line.lower() for s in ('spain', 'spanish', 'spaniard'))\n",
      "\n",
      "spanishLines = lines.filter(findspains)\n",
      "spanishLines.take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[u'4039767598161660860\\tVeterans of the Spanish Civil War who died in 2008',\n",
        " u'2070906922859731078\\tSpanish Navy',\n",
        " u'8352492354729039846\\tSpain Rodriguez',\n",
        " u'4107623939804635096\\tSpanish Campaign Medal',\n",
        " u'4500232227545139240\\tSpanish language',\n",
        " u'3699899586990691050\\tWar of the Spanish Succession',\n",
        " u'7096547112165710084\\tSpain',\n",
        " u'6638185825764543016\\tList of ambassadors of the United Kingdom to Spain']"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines.filter(lambda line: 'spain' in line.lower()).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[u'8352492354729039846\\tSpain Rodriguez',\n",
        " u'7096547112165710084\\tSpain',\n",
        " u'6638185825764543016\\tList of ambassadors of the United Kingdom to Spain']"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}