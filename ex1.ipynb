{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Spark exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## README\n",
      "Download Spark binaries [here](http://spark.apache.org/downloads.html) or directly\n",
      "[here](http://www.apache.org/dyn/closer.cgi/spark/spark-1.2.0/spark-1.2.0-bin-hadoop2.4.tgz)\n",
      "\n",
      "Resources:\n",
      "\n",
      "+ [Spark Programming Guide (v1.2.0)](http://spark.apache.org/docs/latest/programming-guide.html)\n",
      "\n",
      "+ [Spark Python API Docs](http://spark.apache.org/docs/latest/api/python/index.html)\n",
      "\n",
      "+ [Spark training resources](http://databricks.com/spark-training-resources) and [code+data download](http://training.databricks.com/workshop/usb.zip) (thanks to *Databricks*)\n",
      "\n",
      "+ [pyspark-pictures](http://nbviewer.ipython.org/github/jkthompson/pyspark-pictures/blob/master/pyspark-pictures.ipynb) : Learn the pyspark API through pictures and simple examples (thanks to *jkthompson*)\n",
      "\n",
      "+ Spark on AWS, exercises applied to NLP (thanks to *utcompling*): [Ex1](https://github.com/utcompling/applied-nlp/wiki/Spark-AWS-Exercise1) [Ex2](https://github.com/utcompling/applied-nlp/wiki/Spark-AWS-Exercise2)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hello Scala!\n",
      "\n",
      "Launch spark-shell (localhost, driver/master only):\n",
      "``./bin/spark-shell --master local[4]\n",
      "``\n",
      "\n",
      "Play with the spark-shell:\n",
      "```sc.getConf.toDebugString\n",
      "```\n",
      "\n",
      "Open SparkContext web UI in [localhost:4040](http://localhost:4040)\n",
      "\n",
      "Launch 1-machine \"cluster\" in localhost:\n",
      "``./sbin/start-all.sh\n",
      "``\n",
      "\n",
      "Open Spark master's web UI in [localhost:8080](http://localhost:8080)\n",
      "\n",
      "Launch spark-shell (localhost, driver and worker): \n",
      "``./bin/spark-shell --master spark://<IP>:7077\n",
      "``"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Good Bye Scala! Hello Python!\n",
      "\n",
      "Launch pyspark shell (with ipython notebook support):\n",
      "\n",
      "``\n",
      "PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" ~/herramientas/spark-1.2.0-bin-hadoop2.4/bin/pyspark\n",
      "``"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Exercises"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.context import SparkContext\n",
      "print \"Running Spark Version %s\" % (sc.version)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running Spark Version 1.2.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.conf import SparkConf\n",
      "myconf = SparkConf()\n",
      "print myconf.toDebugString()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark.app.name=pyspark-shell\n",
        "spark.master=local[*]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [1, 2, 3, 4, 5]\n",
      "distData = sc.parallelize(data)\n",
      "print type(distData)\n",
      "distData"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pyspark.rdd.RDD'>\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:364"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distData.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "15"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distData.reduce(lambda a,b : a + b) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "15"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Configuration properties"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.conf import SparkConf\n",
      "myconf = SparkConf()\n",
      "myconf.set('spark.driver.memory', '512m').set(\"spark.app.name\", \"My spark app\")\n",
      "print myconf.toDebugString()\n",
      "sc = SparkContext(conf = myconf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark.app.name=My spark app\n",
        "spark.driver.memory=512m\n",
        "spark.master=local[*]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Another way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SparkContext.setSystemProperty(\"spark.app.name\", \"My spark app 2\")\n",
      "SparkContext.setSystemProperty('spark.driver.memory', '512m')\n",
      "print myconf.toDebugString()\n",
      "sc.stop()\n",
      "sc = SparkContext()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark.app.name=My spark app\n",
        "spark.driver.memory=512m\n",
        "spark.master=local[*]\n",
        "spark.rdd.compress=True\n",
        "spark.serializer.objectStreamReset=100\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Working with text files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = sc.textFile(\"data/graphx-wiki-vertices.txt\")\n",
      "lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "data/graphx-wiki-vertices.txt MappedRDD[1] at textFile at NativeMethodAccessorImpl.java:-2"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[u'6598434222544540151\\tAdelaide Hanscom Leeson',\n",
        " u'7814958205460279317\\tDavid Dodge (novelist)',\n",
        " u'3858831448322232257\\tHoward League for Penal Reform',\n",
        " u'1778261942684788432\\tChelsea Quinn Yarbro',\n",
        " u'4201849915685975228\\tDominick Montiglio']"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "22424"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lineLengths = lines.map(lambda s: len(s))\n",
      "lineLengths.reduce(lambda a, b: a + b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "923158"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def findspains(line):\n",
      "    return any(s in line.lower() for s in ('spain', 'spanish', 'spaniard'))\n",
      "\n",
      "spanishLines = lines.filter(findspains)\n",
      "spanishLines.take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[u'4039767598161660860\\tVeterans of the Spanish Civil War who died in 2008',\n",
        " u'2070906922859731078\\tSpanish Navy',\n",
        " u'8352492354729039846\\tSpain Rodriguez',\n",
        " u'4107623939804635096\\tSpanish Campaign Medal',\n",
        " u'4500232227545139240\\tSpanish language',\n",
        " u'3699899586990691050\\tWar of the Spanish Succession',\n",
        " u'7096547112165710084\\tSpain',\n",
        " u'6638185825764543016\\tList of ambassadors of the United Kingdom to Spain']"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines.filter(lambda line: 'spain' in line.lower()).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[u'8352492354729039846\\tSpain Rodriguez',\n",
        " u'7096547112165710084\\tSpain',\n",
        " u'6638185825764543016\\tList of ambassadors of the United Kingdom to Spain']"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Wordcount"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Count words as wc -w"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordsperline = lines.map(lambda line: len(line.split()))\n",
      "wordsperline.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[4, 4, 6, 4, 3]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordsperline.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "90627"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Another way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = lines.flatMap(lambda line: line.split())\n",
      "words.take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[u'6598434222544540151',\n",
        " u'Adelaide',\n",
        " u'Hanscom',\n",
        " u'Leeson',\n",
        " u'7814958205460279317',\n",
        " u'David',\n",
        " u'Dodge',\n",
        " u'(novelist)',\n",
        " u'3858831448322232257',\n",
        " u'Howard']"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "90627"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Generate counts per word:\n",
      "Doing some cleaning and filtering first"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "def clean(text):\n",
      "    res = re.sub('[^a-z]+', '', text.lower())\n",
      "    return res.strip()\n",
      "cleanwords = words.map(lambda word: clean(word))\n",
      "nonemptywords = cleanwords.filter(lambda word: len(word) > 1)\n",
      "\n",
      "nonemptywords.takeOrdered(10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[u'aaahh',\n",
        " u'aachen',\n",
        " u'aacs',\n",
        " u'aaja',\n",
        " u'aaker',\n",
        " u'aaker',\n",
        " u'aaland',\n",
        " u'aaron',\n",
        " u'aaron',\n",
        " u'aaron']"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use *map* to generate a PairRDD"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordcounts = nonemptywords.map(lambda word: (word, 1))\n",
      "wordcounts.takeOrdered(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "[(u'aaahh', 1),\n",
        " (u'aachen', 1),\n",
        " (u'aacs', 1),\n",
        " (u'aaja', 1),\n",
        " (u'aaker', 1),\n",
        " (u'aaker', 1),\n",
        " (u'aaland', 1),\n",
        " (u'aaron', 1),\n",
        " (u'aaron', 1),\n",
        " (u'aaron', 1)]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And then apply reduceByKey()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordcounts = wordcounts.reduceByKey(lambda a, b: a + b)\n",
      "wordcounts.takeOrdered(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[(u'aaahh', 1),\n",
        " (u'aachen', 1),\n",
        " (u'aacs', 1),\n",
        " (u'aaja', 1),\n",
        " (u'aaker', 2),\n",
        " (u'aaland', 1),\n",
        " (u'aaron', 13),\n",
        " (u'aarons', 1),\n",
        " (u'aaronson', 2),\n",
        " (u'aayiram', 1)]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can chaining all the methods in one line"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordcounts = lines.flatMap(lambda line: line.split()).map(lambda word: clean(word)) \\\n",
      "        .filter(lambda word: len(word) > 1).map(lambda word: (word, 1)) \\\n",
      "    .reduceByKey(lambda a, b: a + b)\n",
      "wordcounts = wordcounts.sortByKey()\n",
      "wordcounts.take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[(u'aaahh', 1),\n",
        " (u'aachen', 1),\n",
        " (u'aacs', 1),\n",
        " (u'aaja', 1),\n",
        " (u'aaker', 2),\n",
        " (u'aaland', 1),\n",
        " (u'aaron', 13),\n",
        " (u'aarons', 1),\n",
        " (u'aaronson', 2),\n",
        " (u'aayiram', 1)]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And store our result in a text file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordcounts.saveAsTextFile(\"data/wordcounts/\") "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Output file can be in CSV format"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csv = wordcounts.map(lambda a: \"%s,%i\" %(a[0],a[1]))\n",
      "csv.saveAsTextFile(\"data/wordcounts_csv/\") "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can sort by word counts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordcounts.map(lambda a: (a[1],a[0])).sortByKey(False).take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "[(3023, u'of'),\n",
        " (1191, u'list'),\n",
        " (1142, u'the'),\n",
        " (704, u'in'),\n",
        " (463, u'berkeley'),\n",
        " (445, u'california'),\n",
        " (443, u'and'),\n",
        " (421, u'united'),\n",
        " (394, u'team'),\n",
        " (368, u'john')]"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordcounts.map(lambda a: (a[1],a[0])).takeOrdered(10, key=lambda x: -x[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[(3023, u'of'),\n",
        " (1191, u'list'),\n",
        " (1142, u'the'),\n",
        " (704, u'in'),\n",
        " (463, u'berkeley'),\n",
        " (445, u'california'),\n",
        " (443, u'and'),\n",
        " (421, u'united'),\n",
        " (394, u'team'),\n",
        " (368, u'john')]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####More examples with PairRDDs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mypair = lines.map(lambda line: line.split('\\t')).map(lambda field: (field[0], field[1]))\n",
      "mypair.takeOrdered(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[(u'1000024064623274528', u\"Vincent P. O'Hara\"),\n",
        " (u'1000025160907185508', u'Vincent McDermott'),\n",
        " (u'1000390882544650673',\n",
        "  u'Wikipedia:Version 1.0 Editorial Team/Visual arts articles by quality log'),\n",
        " (u'1000786168171106841', u'Chinadialogue.net'),\n",
        " (u'1001250453944228904', u'Mike MacDonald (rugby union)')]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "links = sc.textFile(\"data/graphx-wiki-edges.txt\")\n",
      "links.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "u'36359329835505530\\t6843358505416683693'"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This file contains hyperlinks between wikipedia pages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mylinks = links.map(lambda line: line.split('\\t')).map(lambda field: (field[0], field[1]))\n",
      "mylinks.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "[(u'36359329835505530', u'6843358505416683693'),\n",
        " (u'168437400931144903', u'961421098734626813'),\n",
        " (u'168437400931144903', u'1367968407401217879'),\n",
        " (u'168437400931144903', u'2270437664547777682'),\n",
        " (u'168437400931144903', u'2381426201672413470')]"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's join by the first column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myjoin = mypair.join(mylinks)\n",
      "myjoin.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "[(u'6318666534240864577', (u'Nottingham Castle', u'781661258159409243')),\n",
        " (u'204024108237224180', (u'William Gray Purcell', u'1746517089350976281')),\n",
        " (u'3287938922515834035',\n",
        "  (u'John R. Phillips (attorney)', u'4228631675084623881')),\n",
        " (u'2045589670281172877', (u'Johanna Fateman', u'1746517089350976281')),\n",
        " (u'2045589670281172877', (u'Johanna Fateman', u'8262690695090170653'))]"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And prepare a second join (by the second column)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myjoin = myjoin.map(lambda x: (x[1][1], x[1][0]))\n",
      "myjoin.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "[(u'781661258159409243', u'Nottingham Castle'),\n",
        " (u'1746517089350976281', u'William Gray Purcell'),\n",
        " (u'4228631675084623881', u'John R. Phillips (attorney)'),\n",
        " (u'1746517089350976281', u'Johanna Fateman'),\n",
        " (u'8262690695090170653', u'Johanna Fateman')]"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myjoin2 = myjoin.join(mypair)\n",
      "myjoin2.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "[(u'8264321909288731877', (u'Berkeley Middle School', u'School band')),\n",
        " (u'6654235025686786086', (u'Berkeley Vincent', u'Hindenburg Line')),\n",
        " (u'8263111968771891409',\n",
        "  (u'List of University of California, Berkeley alumni in politics and government',\n",
        "   u'Trade union')),\n",
        " (u'2681831712398616933',\n",
        "  (u'Berkeley Springs State Park', u'List of West Virginia state parks')),\n",
        " (u'5556710467414394730', (u'George Berkeley', u'Perspective (graphical)'))]"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cleaning it up"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myjoin2 = myjoin2.map(lambda x: (x[1][0], x[1][1]))\n",
      "myjoin2.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[(u'Berkeley Middle School', u'School band'),\n",
        " (u'Berkeley Vincent', u'Hindenburg Line'),\n",
        " (u'List of University of California, Berkeley alumni in politics and government',\n",
        "  u'Trade union'),\n",
        " (u'Berkeley Springs State Park', u'List of West Virginia state parks'),\n",
        " (u'George Berkeley', u'Perspective (graphical)')]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And filtering to look for something"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = 'Turing'\n",
      "myjoin2.filter(lambda x: s in x[0] or s in x[1]).take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "[(u'List of Turing Award laureates by university affiliation', u'Uc berkeley'),\n",
        " (u'List of University of California, Berkeley faculty', u'Turing Award'),\n",
        " (u'List of University of California, Berkeley alumni', u'Turing Award'),\n",
        " (u'University of California, Berkeley', u'Turing Award')]"
       ]
      }
     ],
     "prompt_number": 34
    }
   ],
   "metadata": {}
  }
 ]
}